{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Малков Кирилл.\n",
    "М8О-114СВ-24\n",
    "Лабораторная работа 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизация гиперпараметров \n",
    "     1. С помощью [optuna]() взять пример, аналогичный третьему туториалу документации, используя sklearn и с другим датасетом, выбрать другие  алгоритмы классификации и клстеризации не из туториала  и визуализировать графики для полученного процесса\n",
    "        1. В качестве других моделей подойдут любые алгоритмы классификации и регрессии из sklearn которые не использовались в туториале\n",
    "     2. Использовать 2 разных семплера и прунера\n",
    "     3. При процессе оптимизации гиперпараметров использовать общую память через postgreSQL\n",
    "     4. В качестве отчёта выступают: исходный код, инструкция запуска реляционной БД. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был inear_model.SGDClassifier(alpha=alpha)\n",
    "https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/003_efficient_optimization_algorithms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in .\\env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in .\\env\\lib\\site-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: plotly in .\\env\\lib\\site-packages (5.24.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in .\\env\\lib\\site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in .\\env\\lib\\site-packages (from plotly) (24.2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Plotly express requires pandas to be installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall pandas\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall plotly\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m     19\u001b[0m POSTGRESQL_URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgresql://postgres:1235@localhost:5432/optuna_db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Create Optuna study with PostgreSQL storage\u001b[39;00m\n",
      "File \u001b[1;32mc:\\мага\\ai\\laba3\\env\\Lib\\site-packages\\plotly\\express\\__init__.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m pd \u001b[38;5;241m=\u001b[39m optional_imports\u001b[38;5;241m.\u001b[39mget_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\\\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mPlotly express requires pandas to be installed.\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_imshow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imshow\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chart_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     scatter,\n\u001b[0;32m     17\u001b[0m     scatter_3d,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     density_mapbox,\n\u001b[0;32m     55\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: Plotly express requires pandas to be installed."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler, GridSampler\n",
    "from optuna.pruners import MedianPruner, SuccessiveHalvingPruner\n",
    "from sklearn.datasets import load_wine, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import accuracy_score, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pip install pandas\n",
    "%pip install plotly\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "POSTGRESQL_URL = \"postgresql://postgres:1235@localhost:5432/optuna_db\"\n",
    "\n",
    "# Create Optuna study with PostgreSQL storage\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)  # Reduce log verbosity for clarity\n",
    "storage = optuna.storages.RDBStorage(url=POSTGRESQL_URL)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=TPESampler(), pruner=MedianPruner(), storage=storage, study_name=\"classification\", load_if_exists=True)\n",
    "\n",
    "# Load datasets\n",
    "wine = load_wine()\n",
    "X_class, y_class = wine.data, wine.target\n",
    "X_cluster, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "X_class = scaler.fit_transform(X_class)\n",
    "X_cluster = scaler.fit_transform(X_cluster)\n",
    "\n",
    "# Split data for classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
    "\n",
    "def objective_classification(trial):\n",
    "    # Select model\n",
    "    model_name = trial.suggest_categorical(\"model\", [\"RandomForest\", \"KNeighbors\"])\n",
    "    \n",
    "    if model_name == \"RandomForest\":\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 10, 200)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 20)\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    elif model_name == \"KNeighbors\":\n",
    "        n_neighbors = trial.suggest_int(\"n_neighbors\", 2, 15)\n",
    "        weights = trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"])\n",
    "        clf = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def objective_clustering(trial):\n",
    "    # Select model\n",
    "    model_name = trial.suggest_categorical(\"model\", [\"KMeans\", \"DBSCAN\"])\n",
    "    \n",
    "    if model_name == \"KMeans\":\n",
    "        n_clusters = trial.suggest_int(\"n_clusters\", 2, 10)\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        labels = kmeans.fit_predict(X_cluster)\n",
    "    elif model_name == \"DBSCAN\":\n",
    "        eps = trial.suggest_float(\"eps\", 0.1, 1.0)\n",
    "        min_samples = trial.suggest_int(\"min_samples\", 2, 10)\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(X_cluster)\n",
    "    \n",
    "    # Use silhouette score for clustering performance\n",
    "    if len(set(labels)) > 1:  # Avoid errors for single-cluster cases\n",
    "        return silhouette_score(X_cluster, labels)\n",
    "    else:\n",
    "        return -1.0  # Invalid result for single-cluster\n",
    "\n",
    "# Optimize classification\n",
    "study.optimize(objective_classification, n_trials=50)\n",
    "\n",
    "# Optimize clustering\n",
    "study_clustering = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=GridSampler({\n",
    "        \"model\": [\"KMeans\", \"DBSCAN\"],\n",
    "        \"n_clusters\": list(range(2, 11)),  # For KMeans\n",
    "        \"eps\": [0.1 * i for i in range(1, 11)],  # For DBSCAN\n",
    "        \"min_samples\": list(range(2, 11))  # For DBSCAN\n",
    "    }),\n",
    "    pruner=SuccessiveHalvingPruner(),\n",
    "    storage=storage,\n",
    "    study_name=\"clustering\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "study_clustering.optimize(objective_clustering, n_trials=30)\n",
    "\n",
    "# Visualization\n",
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "optuna.visualization.plot_param_importances(study).show()\n",
    "optuna.visualization.plot_optimization_history(study_clustering).show()\n",
    "optuna.visualization.plot_param_importances(study_clustering).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package           Version\n",
      "----------------- -----------\n",
      "alembic           1.14.0\n",
      "asttokens         3.0.0\n",
      "colorama          0.4.6\n",
      "colorlog          6.9.0\n",
      "comm              0.2.2\n",
      "contourpy         1.3.1\n",
      "cycler            0.12.1\n",
      "debugpy           1.8.11\n",
      "decorator         5.1.1\n",
      "executing         2.1.0\n",
      "fonttools         4.55.3\n",
      "greenlet          3.1.1\n",
      "ipykernel         6.29.5\n",
      "ipython           8.31.0\n",
      "jedi              0.19.2\n",
      "joblib            1.4.2\n",
      "jupyter_client    8.6.3\n",
      "jupyter_core      5.7.2\n",
      "kiwisolver        1.4.7\n",
      "Mako              1.3.8\n",
      "MarkupSafe        3.0.2\n",
      "matplotlib        3.10.0\n",
      "matplotlib-inline 0.1.7\n",
      "nest-asyncio      1.6.0\n",
      "numpy             2.2.1\n",
      "optuna            4.1.0\n",
      "packaging         24.2\n",
      "pandas            2.2.3\n",
      "parso             0.8.4\n",
      "pillow            11.0.0\n",
      "pip               24.0\n",
      "platformdirs      4.3.6\n",
      "plotly            5.24.1\n",
      "prompt_toolkit    3.0.48\n",
      "psutil            6.1.1\n",
      "psycopg2          2.9.10\n",
      "pure_eval         0.2.3\n",
      "Pygments          2.18.0\n",
      "pyparsing         3.2.0\n",
      "python-dateutil   2.9.0.post0\n",
      "pytz              2024.2\n",
      "pywin32           308\n",
      "PyYAML            6.0.2\n",
      "pyzmq             26.2.0\n",
      "scikit-learn      1.6.0\n",
      "scipy             1.14.1\n",
      "six               1.17.0\n",
      "SQLAlchemy        2.0.36\n",
      "stack-data        0.6.3\n",
      "tenacity          9.0.0\n",
      "threadpoolctl     3.5.0\n",
      "tornado           6.4.2\n",
      "tqdm              4.67.1\n",
      "traitlets         5.14.3\n",
      "typing_extensions 4.12.2\n",
      "tzdata            2024.2\n",
      "wcwidth           0.2.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
